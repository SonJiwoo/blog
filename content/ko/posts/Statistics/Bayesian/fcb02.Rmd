---
collapsible: false
date: "2021-01-07T10:08:56+09:00"
description: Belief, Probability and Exchangeability
draft: false
title: Exchangeability
weight: 2
---

## Chapter 02. <br> Belief, Probability and Exchangeability
본 포스팅은 **First Course in Bayesian Statistical Methods**를 참고하였다.
이번 장의 목표는 independence와 exchangeability를 이해하는 것이다. 이를 바탕으로 de Finetti's theorem이 Bayesian에 갖는 의의를 이해한다면, 베이즈 통계를 공부할 준비가 된 것이다.

### Belief functions and Probabilities
`$Be()$`는 belief function이라고 하자. 예를 들어, `$Be(F) > Be(G)$`는  G보다 F를 더 믿는다고 해석하면 된다. F, G, H를 아래와 같은 각각의 상황이라고 가정해보자.

> F : 좌파 후보자를 투표하는 경우 <br>
G : 소득이 하위 10%에 속하는 경우 <br>
H : 대도시에 거주하는 경우

###### Axioms of beliefs
1. `$Be($`not `$H|H) \le Be(F|H) \le Be(H|H)$`
2. `$Be(F $` or `$G|H) \ge max(Be(F|H), Be(G|H))$`
3. `$Be(F $` and `$G|H)$` can be drvied from `$Be(G|H)$` and `$Be(F|G $` and `$H)$`

###### Axioms of probability
1. `$0 = Pr($`not `$H|H) \le Pr(F|H) \le Pr(H|H) \le = 1$`
2. `$Pr(F \cup G|H) = Pr(F|H) + Pr(G|H)$` if `$F \cap G = \emptyset$`
3. `$Pr(F \cap G|H) = Pr(G|H)Pr(F|g \cap H)$`

belief와 probability에 대한 각각의 공리들이 매칭되므로, 우리는 믿음의 정도를 계산할 때 확률함수를 계산하는 것처럼 다뤄도 무방하다고 결론낼 수 있다.

### Independence
사건 F와 G는 아래와 같은 상황에서 **조건부 독립**(`conditional independence`)이라고 한다.
$$Pr(F \cap G|H) = Pr(F|H)Pr(G|H)$$
이를 풀어서 해석해보자면, H를 알고 있는 상황에서, 추가적으로 G에 대해서 알게 되는 것은 F에 대한 믿음을 변화시키는 데에 영향이 없다는 것이다.

### Exchangeability
`$Y_1, ..., Y_n$`이 있을 때, 이 순서를 어떻게 섞더라도 결합확률은 바꾸지 않을 때 `exchangeable`하다고 한다. 이는 직관적으로 풀어쓴 것이며, 다시 한 번 수학적 정의로 자세히 써보자면 아래와 같다.
<br> <br>
Let `$p(y_1, ... y_n)$` be the joint density of `$Y_1, ..., Y_n$`. If `$p(y_1, ..., y_n) = p(y_{\pi_1}, ..., y_{\pi_n})$` for all permutations `$\pi$` of {1, ..., n}, then `$Y_1, ..., Y_n$` are exchangeable.

$$\begin{equation}
  \left.\begin{aligned}
  Y_1, ..., Y_n|\theta \text{ i.i.d} \\ 
  \theta \sim p(\theta)
\end{aligned}\right\} \Rightarrow Y_1, ... Y_n \text{ are exchangeable}
\end{equation}$$

### de Finetti's Theorem
만약 `$Y_1, ..., Y_n$`이 exchangeability를 만족한다면, 아래와 같이 말할 수 있다.

$$p(y_1, ..., y_n) = \int{\Bigg\{\prod_{1}^{n}p(y_i|\theta)\Bigg\} \:p(\theta)d\theta} \\
\text{for some parameter} \: \theta$$

이는 확률변수 `$Y_1, ..., Y_n$`에 대해서 exchangeability를 만족한다면, `$p(y_1, ..., y_n)$`에 대해 `$\theta$`라는 parameter를 활용하여 위와 같은 수식으로 나타낼 수 있다는 것이다. <br> <br>

그렇다면 이 정리가 베이지안에게 어떤 의미를 갖는 것일까? 이는 사전확률분포(prior model)와 가능도함수(sampling model)가 belief model `$p(y_1, ..., y_n)$`에 의존함을 의미한다. 풀어서 이야기하자면, parameter `$\theta$`가 확률론자가 주장하는 것처럼 미지의 고정된 값이 아니라, 어떤 분포를 갖는 확률변수로 볼 수 있다는 것이다. (그리고 그것을 우리는 사전확률분포 prior distribution이라고 부른다.)

### 주의사항
**Bayes' rule**은 데이터를 접한 이후, 우리의 믿음이 어떻게 업데이트되는지에 대한 수식이다.
여기서 헷갈리면 안되는 것이 있다. **Bayes' rule**은 우리의 믿음이 어때야 하는지(`should be`)에 대해서 이야기하고 있는 것이 아니라 어떻게 변해야 하는지(`should change`)에 대해서 이야기하는 것이다.

### Conclusion
<p style='text-align: center'> 믿음(Belief)도 확률(Probability)로써 이야기할 수 있다. </p> <br>
<p style='text-align: center'> paramter `$\theta$`는 분포를 갖는 확률변수이다. </p> <br>

---
<br> 
<p style='text-align: center; color:gray'> 혹시 궁금한 점이나 잘못된 내용이 있다면, 댓글로 알려주시면 적극 반영하도록 하겠습니다. </p>

<br>
<br>